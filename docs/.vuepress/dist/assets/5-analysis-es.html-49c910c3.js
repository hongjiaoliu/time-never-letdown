const e=JSON.parse('{"key":"v-249b1944","path":"/enterprise/es/5-analysis-es.html","title":"5-分词","lang":"zh-CN","frontmatter":{"icon":"edit","date":"2022-05-05T00:00:00.000Z","category":["Java企业开发"],"tag":["ElasticSearch"],"star":false,"description":"5-分词 简介 https://www.elastic.co/guide/en/elasticsearch/reference/7.x/analysis.html 一个tokenizer（分词器）接收一个字符流，将之分割为独立的tokens（词元，通常是独立的单词），然后输出tokens流。 例如：whitespace tokenizer遇到空白字符时分割文本。它会将文本“Quick brown fox!”分割为[Quick,brown,fox!]。 该tokenizer（分词器）还负责记录各个terms(词条)的顺序或position位置（用于phrase短语和word proximity词近邻查询），以及term（词条）所代表的原始word（单词）的start（起始）和end（结束）的character offsets（字符串偏移量）（用于高亮显示搜索的内容）。 elasticsearch提供了很多内置的分词器，可以用来构建custom analyzers（自定义分词器）。","head":[["meta",{"property":"og:url","content":"https://liuhongjiao.cn/enterprise/es/5-analysis-es.html"}],["meta",{"property":"og:site_name","content":"L - 时光不负"}],["meta",{"property":"og:title","content":"5-分词"}],["meta",{"property":"og:description","content":"5-分词 简介 https://www.elastic.co/guide/en/elasticsearch/reference/7.x/analysis.html 一个tokenizer（分词器）接收一个字符流，将之分割为独立的tokens（词元，通常是独立的单词），然后输出tokens流。 例如：whitespace tokenizer遇到空白字符时分割文本。它会将文本“Quick brown fox!”分割为[Quick,brown,fox!]。 该tokenizer（分词器）还负责记录各个terms(词条)的顺序或position位置（用于phrase短语和word proximity词近邻查询），以及term（词条）所代表的原始word（单词）的start（起始）和end（结束）的character offsets（字符串偏移量）（用于高亮显示搜索的内容）。 elasticsearch提供了很多内置的分词器，可以用来构建custom analyzers（自定义分词器）。"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:tag","content":"ElasticSearch"}],["meta",{"property":"article:published_time","content":"2022-05-05T00:00:00.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"5-分词\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2022-05-05T00:00:00.000Z\\",\\"dateModified\\":null,\\"author\\":[]}"]]},"headers":[{"level":2,"title":"1. 下载","slug":"_1-下载","link":"#_1-下载","children":[]},{"level":2,"title":"2. 解压","slug":"_2-解压","link":"#_2-解压","children":[]},{"level":2,"title":"3. 查看安装的ik插件","slug":"_3-查看安装的ik插件","link":"#_3-查看安装的ik插件","children":[]},{"level":2,"title":"4. 测试 ik 分词器","slug":"_4-测试-ik-分词器","link":"#_4-测试-ik-分词器","children":[]},{"level":2,"title":"1. nginx 中自定义分词文件","slug":"_1-nginx-中自定义分词文件","link":"#_1-nginx-中自定义分词文件","children":[]},{"level":2,"title":"2. 给 es 配置自定义词库","slug":"_2-给-es-配置自定义词库","link":"#_2-给-es-配置自定义词库","children":[]},{"level":2,"title":"3. 重启 elasticsearch 容器","slug":"_3-重启-elasticsearch-容器","link":"#_3-重启-elasticsearch-容器","children":[]},{"level":2,"title":"4. 测试自定义词库","slug":"_4-测试自定义词库","link":"#_4-测试自定义词库","children":[]}],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":3.82,"words":1147},"filePathRelative":"enterprise/es/5-analysis-es.md","localizedDate":"2022年5月5日","excerpt":"<h1> 5-分词</h1>\\n<h1> 简介</h1>\\n<blockquote>\\n<p><a href=\\"https://www.elastic.co/guide/en/elasticsearch/reference/7.x/analysis.html\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">https://www.elastic.co/guide/en/elasticsearch/reference/7.x/analysis.html</a></p>\\n</blockquote>\\n<p>一个tokenizer（分词器）接收一个字符流，将之分割为独立的tokens（词元，通常是独立的单词），然后输出tokens流。\\n例如：whitespace tokenizer遇到空白字符时分割文本。它会将文本“Quick brown fox!”分割为[Quick,brown,fox!]。\\n该tokenizer（分词器）还负责记录各个terms(词条)的顺序或position位置（用于phrase短语和word proximity词近邻查询），以及term（词条）所代表的原始word（单词）的start（起始）和end（结束）的character offsets（字符串偏移量）（用于高亮显示搜索的内容）。\\nelasticsearch提供了很多内置的分词器，可以用来构建custom analyzers（自定义分词器）。</p>","autoDesc":true}');export{e as data};
